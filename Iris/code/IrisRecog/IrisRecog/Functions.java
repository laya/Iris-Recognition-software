package IrisRecog;/** * Functions.java * * Abstract class defines the static functions used throughout the * application. * */import java.io.*;import javax.swing.*;import java.net.*;import java.awt.*;import java.awt.image.*;import java.util.*;public abstract class Functions{	/**	 * Returns the lowercase extension of a file.	 *	 * @param f The file	 * @return the extension	 */    public static String getExtension(File f)    {        String str_Extension = null;        String str_FileName = f.getName();        int i = str_FileName.lastIndexOf('.');        if (i > 0 &&  i < str_FileName.length() - 1)        {            str_Extension = str_FileName.substring(i+1).toLowerCase();        }        return str_Extension;    }  	/**  	 * Creates an image icon from the specified path.  	 *  	 * @param path The string path to the file used to create the image icon  	 * @return the image icon created  	 */    public static ImageIcon createImageIcon(String path)    {        URL url_Image = Functions.class.getResource(path);        if (url_Image != null)        	return new ImageIcon(url_Image);        else            return null;    }    /**     * Converts the image into an integer double array of grayscale color.     *     * @param img The image to be converted     * @return the integer double array     */    public static int [][] convertToGrayscale(Image img)    {    	PixelGrabber pgb_PixelGrabber;    	Color clr_Tmp;    	//Ensure the image is loaded completely    	new ImageIcon(img).getImage();		//Save the width and height of the image		int int_Width = img.getWidth(null);		int int_Height = img.getHeight(null);		//Allocate new integer double array to hold all of the pixels in the image		int [][] int_Arr_Pixels = new int [int_Width][int_Height];		//Allocated array to send to pixel grabber - NOTE: this is a one dimensional array		int [] int_Dar_AllPix = new int [int_Width * int_Height];        try        {        	pgb_PixelGrabber = new PixelGrabber(img, 0, 0, int_Width, int_Height, int_Dar_AllPix, 0, int_Width);	        pgb_PixelGrabber.grabPixels();	        /* Convert one dimensional array to two dimensional array */	     	for(int i = 0; i < img.getWidth(null); i++)	     	{	     		for(int j = 0; j < img.getHeight(null); j++)	     		{	     			clr_Tmp = new Color(int_Dar_AllPix[(j * img.getWidth(null)) + i]);					//Compute the grayscale of the color with the weights given (these are well documented)	     			int_Arr_Pixels[i][j] = (int)(0.3 * clr_Tmp.getRed() + 0.59 * clr_Tmp.getGreen() + 0.11 * clr_Tmp.getBlue());	      		}	     	}     	}     	catch(Exception e)     	{     		e.printStackTrace();     	}     	return int_Arr_Pixels;    }	/**	 * Counts the number of pixels directly to the right that have an intensity	 * below the threshhold. (The similarity is depended on the variance)	 *	 * @param img The image to search	 * @param x The x location of the pixel that starts the block	 * @param y The y location of the pixel that starts the block	 * @return the counts of pixels to the right of the starting point that have	 *   	   similar intensity	 */	public static int getCountPixelsToRightBelowThreshhold(MedianImage img, int x, int y, int t)	{		int int_Pixels = 1;		//While the pixel is in the image and has an intesnity less than the intensity of		//starting pixel (scaled by a variance).		while( (x + int_Pixels) < img.getWidth() && img.getIntensity(x + int_Pixels, y) <= t )		{			int_Pixels++; //increment pixel count		}		return int_Pixels;	}	/**	 * Determines if the vertical band going through the center of the block only contains	 * pixels that are less than the intensity of the block starting pixel.	 *	 * @param img The image to use in matching the band to the block start intensity	 * @param x The x location of the pixel that starts the block	 * @param y The y location of the pixel that starts the block	 * @return true if all of the pixels in the vertical band have intensities less	 * 		   than the block starting pixel	 */	public static boolean verticalBlockBelowThreshhold(MedianImage img, int x, int y, int blockSize)	{		//Get the size of the vertial band, which is a percentage portion of the block size (x2 in each direction)		int int_VerticalBlockSize = (int)((blockSize / 2) * Globals.PUPIL_BLOCK_SIZE_PORTION);		//Get the intensity of the block starting pixel		int int_Intensity = img.getIntensity(x, y);		if(y - int_VerticalBlockSize < 0)			return false;		//For y values of -verticalBlockSize to +verticalBlockSize		for(int i = (-1 * int_VerticalBlockSize); i <= int_VerticalBlockSize; i++)		{			//If the intensity at the current pixel is greater than the block			//starting pixel's intensity, return false			if(img.getIntensity(x, y + i) >= (int_Intensity + Globals.PUPIL_VARIANCE) )			{				return false;			}		}		return true;	}	/**	 * Returns the value of the pixel with the lowest intensity in the image.	 *	 * @param img The image to be searched for its lowest intensity	 * @return the lowest intensity found in the image	 */	public static int lowestIntensity(MedianImage img)	{		int int_Min = 255; //set default minimum to the maximum 8-bit intensity		int int_Tmp = int_Min;		//For each row in the image		for(int i = 0; i < img.getWidth(); i++)		{			//For each column in the image			for(int j = 0; j < img.getHeight(); j++)			{				//Retrieve the intensity of the pixel at the row, column				int_Tmp = img.getIntensity(i, j);				//If the intensity is less than the current minimum, update				if(int_Tmp < int_Min)					int_Min = int_Tmp;			}		}		return int_Min;	}	/**	 * Converts the given polar coordinate, with a center of reference, to	 * cartesian point.	 *	 * @param center The point to be used as the center or the coordinate system	 * @param theta The angle portion of the polar coordinate	 * @param r The radius porition of the polar coordinate	 * @return Point The cartesian equivalent of the polar coordinate	 */	public static Point polarToCartesian(Point center, double theta,    double r)	{		int int_X = (int)(Math.cos(theta) * r) + (int)(center.getX());		int int_Y = (int)(Math.sin(theta) * r) + (int)(center.getY());		return new Point(int_X, int_Y);	}	/**	 * Determines the amount of pixels, rather percentage of total amount of pixels,	 * laying on the edge of a circle defined the the center point and radius	 * that have an intensity in the given image that is equal to zero (black).	 * The function is meant to be applied to an image that has undergone canny	 * edge detection and therefore only consists of pixels that are either black or	 * white.	 *	 * @param img The image from which to test	 * @param center The center point of the circle to test	 * @param radius The radius of the circle to test	 * @return double The percentage of the total pixels in the defined circle that are black	 */	public static double circleOfBlackPixels(GrayscaleImage img, Point center, double radius)	{		int int_Pixels = 0;		//For each degree in the circle		for(int theta = 0; theta < 360; theta++)		{			//If any of the intensities in nearby circles pixels are black			if( img.getIntensity(center, theta, radius - 3) == 0 ||				img.getIntensity(center, theta, radius - 2) == 0 ||				img.getIntensity(center, theta, radius - 1) == 0 ||				img.getIntensity(center, theta, radius) == 0 ||				img.getIntensity(center, theta, radius + 1) == 0 ||				img.getIntensity(center, theta, radius + 2) == 0 ||				img.getIntensity(center, theta, radius + 3) == 0)			{				int_Pixels++; //increment pixel count			}		}		//return percentage of total pixels that are black		return (double)int_Pixels / 360;	}	/**	 * Subtracts the second unwrapped image from the first using absolute value of	 * differences and returns the result.	 *	 * @param img1 The first unwrapped image	 * @param img2 The second unwrapped image	 * @return UnwrappedImage The absolute subtraction of the two images	 */	public static UnwrappedImage subtractAbsolute(GrayscaleImage img1, GrayscaleImage img2)	{		//Create subtraction image to use to return		UnwrappedImage uwr_Subtraction = new UnwrappedImage(Constants.INT_UNWRAPPED_WIDTH, Constants.INT_UNWRAPPED_HEIGHT);		//For each x		for(int i = 0; i < Constants.INT_UNWRAPPED_WIDTH; i++)		{			//For each y			for(int j = 0; j < Constants.INT_UNWRAPPED_HEIGHT; j++)			{				//Set value at x, y location to the absolute value of the result of the subtraction				uwr_Subtraction.setIntensity(i, j, Math.abs(img1.getIntensity(i, j) - img2.getIntensity(i, j) ));			}		}		//Return the subtractiong image		return uwr_Subtraction;	}	/**	 * Serializes the agent object by serializing the memory of the agent to the	 * specified file.	 *	 * @param f The file to serialize the agent's memory to	 * @param a The agent whose memory is to be serialized to the file	 */	public static void serializeAgent(File f, Agent a)	{		try		{			FileOutputStream fos_FileOutputStream = new FileOutputStream(f);	        ObjectOutputStream oos_ObjectOutputStream = new ObjectOutputStream(fos_FileOutputStream);	        oos_ObjectOutputStream.writeObject(a.getMemory()); //Serialize the memory object of the agent	        oos_ObjectOutputStream.close();	    }	    catch(Exception e)	    {	    	e.printStackTrace();	    }	}	/**	 * Deserializes the agent object by deserializing the memory of the agent	 * from the specified file. This process returns the memory as a result.	 *	 * @param f The file to deserialize the agent's memory from	 * @return Memory The memory contents in the specified file	 */	public static Memory deserializeAgent(File f)	{		Memory mem_Ret = null;		try		{			FileInputStream fis_FileInputStream = new FileInputStream(f);	        ObjectInputStream ois_FileInputStream = new ObjectInputStream(fis_FileInputStream);	        mem_Ret = (Memory)ois_FileInputStream.readObject(); //deserialize the memory object from the file	        ois_FileInputStream.close();        }	    catch(Exception e)	    {	    	e.printStackTrace();	    }        return mem_Ret;	}	/**	 * Applies a median filter to the subject, whereby creatinga  median image	 * that is stored in the subject object. The median filter works by using	 * a window size that dictates the grid of pixels used in the median computation.	 * A window size of 3, for example, indicates that a window of 7 x 7 is to	 * be used (3 pixels to left, 3 pixels above, 3 pixels to right and 3 pixels	 * below the center).	 *	 * EX: 	Window Size = 3 where c is the center of the window	 *	 *		X X	X X	X X X	 *		X X	X X	X X X	 *		X X	X X	X X X	 *		X X	X c	X X X	 *		X X	X X	X X X	 *		X X	X X	X X X	 *		X X	X X	X X X	 *	 * The function uses a window on every pixel (starting in and down the width	 * and height of the window size and going to the window size from from the	 * right and bottom, whereby avoiding going beyond the bounds of the image).	 * All of the values in the window are put into a list, sorted and the median	 * value (middle) is used as the intensity for the center pixel. This algorithm	 * is good for reducing minor artifacts in the image such as noise.	 *	 * @param s The subject whom is to have the median filter applied to	 */	public static void applyMedianFilter(Subject s)	{    	GrayscaleImage gmg_Img = s.getGrayscaleImage(); //get the grayscale version of the eye image		MedianImage mim_MedianImage = new MedianImage(gmg_Img.getWidth(), gmg_Img.getHeight());		int int_WindowSize = Globals.MEDIAN_FILTER_WINDOW_SIZE;		int [] int_Arr_Buffer = new int[((2*int_WindowSize)+1) * ((2*int_WindowSize)+1)];		int int_MedianIndex = int_Arr_Buffer.length / 2;		int int_Index;		//For each row in the image		for(int y = int_WindowSize; y < gmg_Img.getHeight() - int_WindowSize; y++)		{			//For each column in the image			for(int x = int_WindowSize; x < gmg_Img.getWidth() - int_WindowSize; x++)			{				int_Index = 0;				//Add each of the values from the neighboring area to the array				for(int i = x - int_WindowSize; i < x + int_WindowSize; i++)				{					for(int j = y - int_WindowSize; j < y + int_WindowSize; j++)					{						int_Arr_Buffer[int_Index++] = gmg_Img.getIntensity(i, j);					}				}				//Sort the array so that we can find the median				Arrays.sort(int_Arr_Buffer);				mim_MedianImage.setIntensity(x, y, int_Arr_Buffer[int_MedianIndex]);			}		}		//Set the median image of the subject to the median image created		s.setMedianImage(mim_MedianImage);	}	/**	 *	 */	public static UnwrappedImage meanFilter(Identity img)	{    	UnwrappedImage uwr_Img = img.getIdentityIris();		MedianImage mim_MeanImage = new MedianImage(uwr_Img.getWidth(), uwr_Img.getHeight());		int int_WindowSize = 2;		int int_Sum;		int int_NumPixels = ((2*int_WindowSize)+1) * ((2*int_WindowSize)+1);		//For each row in the image		for(int y = int_WindowSize; y < uwr_Img.getHeight() - int_WindowSize; y++)		{			//For each column in the image			for(int x = int_WindowSize; x < uwr_Img.getWidth() - int_WindowSize; x++)			{				int_Sum = 0;				//Add each of the values from the neighboring area to the array				for(int i = x - int_WindowSize; i < x + int_WindowSize; i++)				{					for(int j = y - int_WindowSize; j < y + int_WindowSize; j++)					{						int_Sum += uwr_Img.getIntensity(i,j);					}				}				//Set the pixel to the value of the median of the buffer				mim_MeanImage.setIntensity(x, y, int_Sum / int_NumPixels);			}		}		return uwr_Img;	}	/**	 * Finds the center of the pupil of the given subject. The algorithm scans through	 * the median image from top left to bottom right and makes no assumptions about the	 * position of the pupil (or eye for that matter). The algorithm begins by finding	 * a pixel that is below the threshhold (a combination of the lowest intensity in the	 * current image and some variance) and finds the amount of pixels adjacent to the	 * right that have an intensity below the threshhold as well. This amount is called the	 * block size. The center of the block is the suspected center of the pupil. If this	 * block is the largest observed so far it determines if a block of pixels	 * going in the vertical direction up and down from the center of the block (effectively	 * making a cross) are also below the threshold and some variance. If so, the maximum	 * block size is updated and the center to return is reset to new center.	 *	 * @param s The subject	 */	public static void detectPupilCenter(Subject s)    {    	MedianImage mim_Img = s.getMedianImage(); //get the grayscale version of the eye image		Point pnt_Center = new Point(mim_Img.getWidth(),mim_Img.getHeight()); //default center to center of the subject's eye image		int int_IntensityBase = lowestIntensity(mim_Img);		int int_MaxBlockSize = 0;		int int_BlockSize = 0;		//For each row in the image		for(int y = 0; y < mim_Img.getHeight(); y++)		{			//For each column in the image			for(int x = 0; x < mim_Img.getWidth(); x++)			{				//If the intensity at the current pizel is less than the threshold				if(mim_Img.getIntensity(x, y) < (int_IntensityBase + Globals.PUPIL_VARIANCE))				{					//Find the number of pixels to the right with similar intensity					int_BlockSize = getCountPixelsToRightBelowThreshhold(mim_Img, x, y, (int_IntensityBase + Globals.PUPIL_VARIANCE));					//If the block is larger than 5 pixels, larger than the maximum band accepted					//so far and the vertical band spanning vertically from the center					if(int_BlockSize > int_MaxBlockSize && verticalBlockBelowThreshhold(mim_Img, x + (int_BlockSize/2), y, int_BlockSize))					{						//Set the maximum band width as the block size						int_MaxBlockSize = int_BlockSize;						//Save the center of the band						pnt_Center = new Point(x + (int_BlockSize/2), y);					}					//Advance over pixels that have been checked (left half of the band)					x += int_BlockSize;				}			}		}		//Set the radius found to one more than given to reduce minor errors, effectively		//over estimate the pupil radius		s.setPupilRadius((int_MaxBlockSize/2)+2);       	s.setPupilCenter(pnt_Center);    }    /**     * Using the canny edge detection method, detects the edges of the image     * based on the current threshhold and sigma values. The canny edge detector     * will generate a binay image (black and white) that shows the edges of the     * image. This image is saved into the subject as the edge image.     *     * @param s The subject for which the eye image is to have its edges detected     */    public static void detectEdges(Subject s)    {		CannyEdgeDetector ced_EdgeDetector = new CannyEdgeDetector();		ced_EdgeDetector.setSourceImage(s.getMedianImage()); //Use the median image to detect edges		try		{			ced_EdgeDetector.process(); //Process computes the edges		}		catch(EdgeDetectorException e) { }		s.setEdgeImage(ced_EdgeDetector.getEdgeImage());    }    /**     * Determines the approximate radius of the iris of the given subject. The     * algorithm starts the radius identified by the pupil center detection and     * finds a radius for which the circle in the edge image has at least a certain     * amount of black pixels (edges) on or nearly on the circle. If the proportion     * of the iris radius meeting this criterion is between two bounds then the iris     * radius is successfully found.     *     * @param s The subject     */    public static void detectIrisRadius(Subject s)    {    	GrayscaleImage gmg_EdgeImage;    	Point pnt_PupilCenter = s.getPupilCenter();    	double dbl_IrisRadius = 0;    	double dbl_Radius = 0;    	double dbl_Ratio = 0.0;    	boolean bln_IrisFound = false;		double dbl_StartPercentMatch = Globals.CIRCLE_PERCENT_MATCH;		// While the ratio of the iris radius to the pupil radius is not within the		// acceptable bounds and the percentage match is set to a value greather than zero		while((dbl_Ratio <.20 || dbl_Ratio > .50) && Globals.CIRCLE_PERCENT_MATCH > 0) //need a ratio of iris radius to pupil radius of about .3 to .4		{			//Detect the edges			detectEdges(s);			//Save the edge image of the subject locally			gmg_EdgeImage = s.getEdgeImage();			//Reset vars			bln_IrisFound = false;			dbl_IrisRadius = 0;			//Start 5% of total picture width away from the pupil radius			dbl_Radius = s.getPupilRadius() + (gmg_EdgeImage.getWidth() * .05);			try			{				//While the iris is not found		    	while(!bln_IrisFound)		    	{		    		//Increment radius		    		dbl_Radius++;					//If the percentage of the pixels along the circle defined by the current radius					//and the pupil center that are black is greater than the given threshhold percentage,					//the iris has been found					if(Functions.circleOfBlackPixels(gmg_EdgeImage, pnt_PupilCenter, dbl_Radius) > Globals.CIRCLE_PERCENT_MATCH)					{						bln_IrisFound = true;						dbl_IrisRadius = dbl_Radius;					}		    	}		    }		    catch(Exception e) { }			if(dbl_IrisRadius > 0) //protect divide by zero				dbl_Ratio = s.getPupilRadius() / dbl_IrisRadius;			else				dbl_Ratio = 0;			Globals.CIRCLE_PERCENT_MATCH -= .05; //decrement the percentage match in case the ratio is not accepted		}		Globals.CIRCLE_PERCENT_MATCH = dbl_StartPercentMatch;    	s.setIrisRadius(dbl_IrisRadius-2); //Take a little off radius    }    /**     * Unrolls the iris of the subject, defined as the area between the pupil radius and     * the iris radius. The iris, a circular object is transformed polarly into a rectangular     * image that counteracts the distortion of the wrapping of the iris around the eye.     *     * @param s The subject to have their iris unrolled     */	public static void unrollIris(Subject s)	{		GrayscaleImage gmg_Img = s.getGrayscaleImage();		UnwrappedImage uwr_Unwrapped = new UnwrappedImage(Constants.INT_UNWRAPPED_WIDTH, Constants.INT_UNWRAPPED_HEIGHT);		Point pnt_PupilCenter = s.getPupilCenter();		double dbl_PupilRadius = s.getPupilRadius();		double dbl_IrisRadius = s.getIrisRadius();		double dbl_Theta = 0.0;		double dbl_DeltaR = 0.0;		double dbl_RelativeR = 0.0;		Point pnt_MapTo = null;		Point pnt_MapFrom = null;		//Iterate over the Y values in the output image		for(double MapToY = 0.0; MapToY < uwr_Unwrapped.getHeight(); MapToY ++)		{			//Iterate over the X values in the output image			for(double MapToX = 0.0; MapToX < uwr_Unwrapped.getWidth(); MapToX ++)			{				//Determine the polar angle to the current coordinate				//using the following formula: ANG = 2 * pi * ( X ouput image / width output image)				dbl_Theta = 2 * Math.PI * ( MapToX / uwr_Unwrapped.getWidth() );				pnt_MapTo = new Point((int)MapToX, (int)MapToY);				//Find the distance between the radius of the iris				//and the pupil				dbl_DeltaR = dbl_IrisRadius - dbl_PupilRadius;				//Compute the relative distance from the pupil radius				//to the map from point				dbl_RelativeR = dbl_DeltaR * ( MapToY * 1.0 / uwr_Unwrapped.getHeight() );				//The point to map from is the point located along theta				//at the pupil radius plus the relative radius addition				pnt_MapFrom = Functions.polarToCartesian(pnt_PupilCenter, dbl_Theta, dbl_PupilRadius + dbl_RelativeR);				uwr_Unwrapped.setIntensity(pnt_MapTo, gmg_Img.getIntensity(pnt_MapFrom));			}		}		s.setUnwrappedImage(uwr_Unwrapped);	}	/**	 * Attempts to match the subject against the identity and returns a percentage	 * value of the average percentage difference, per pixel, that the unwrapped	 * image of the subject varies from that stored in the identity,	 *	 * @param s The subject to be matched from	 * @param ident The identity to matched against	 * @return double The average percentage change per pixel between the subject	 *                and the identity	 */	public static double matchIdentity(Subject s, Identity ident)	{		GrayscaleImage gim_Base = s.getUnwrappedImage();		GrayscaleImage gim_CompareImage;		int int_Sum = 0;		//Apply the mean filter to the identity		gim_CompareImage = meanFilter(ident);		//Subtract the compare image from the base image (absolute values)		gim_CompareImage = subtractAbsolute(gim_Base, gim_CompareImage);		//For each column in the image		for(int x = 0; x < gim_CompareImage.getWidth(); x++)		{			//For each row in the image			for(int y = 0; y < gim_CompareImage.getHeight(); y++)			{				//Add to the difference				int_Sum += gim_CompareImage.getIntensity(x, y);			}		}		//Return the average perctentage difference per pixel, scaled by the maximum		//per pixel of 255.		return 1 - ((double)int_Sum / (255 * gim_CompareImage.getWidth() * gim_CompareImage.getHeight()));	}}